Since its inception, the Web has been an open frontier of exploration in software and network system design. New ideas were tried and tested first, but organized and standardized later, once they proved their utility. For example, HTTP\footnote{Hypertext Transfer Protocol}, the transport protocol of the Web, had been in use for more than half a decade before its state of practice was written down as HTTP/1.0~\cite{rfc1945} in May 1996. But the standardization process continued until 1999, when the final revision of HTTP/1.1~\cite{Fielding:1999} standard was completed. The architectural principles behind HTTP and other Web standards were described by Fielding~\cite{Fielding00Phd}, thus completing the process. HTML\footnote{Hypertext Markup Language} has followed a similar path. It started out with a simple set of tags for structuring text and graphics on Web pages. As the number of content types (new multimedia formats, more sophisticated ways of displaying text, interactive Web pages~\cite{Gar05}) grew, the HTML tags were pressed into service of displaying them in various non-standard ways. After nearly two decades of this growth, new multimedia HTML tags were finally added and standardized by W3C\footnote{World Wide Web Consortium} in HTML5, which was completed in 2012~\cite{Hickson2010}.

A similar sequence of events -- simple beginnings leading to an unruly explosion followed by some type of organization -- can be observed in the realm of Web services. Web services concern the way in wich software communicates. Software can come in many forms from a simple script on a personal computer, to an application on a networked server, through to a large operational support system running in a mainframe computer.These scripts, applications and software systems can be viewed as software components, considering the following characteristics of such a software component:

\begin{itemize}
\item It can \textbf{describe} itself -- so that other components can understand the functionality it offers and how to access that functionality,
\item it can allow other components to \textbf{locate} it -- so it can be used when required,
\item it can be readily \textbf{invoked} whenever another component wishes to use its functions.
\end{itemize}

If such a software component were installed in a network, its services could be used by other software components. These components are said to be providing a web service. A \textit{Web service} then, is an interface that describes a collection of operations that are network accesible through standardized messaging and that performs an specific task or set of tasks\cite{Gottschalk:2002,Muschamp:2004}.

The use of web services on the World Wide Web is expanding rapidly as the need for application-to-application communication and interoperability grows. These services provide a standard mean of communication among different software applications involved in presenting dynamic context-driven information to the user\cite{Austin:2004}. An example is a web service that returns a credit rating when provided with user's ID, or an order handling system that provides user and usage data to a billing web service wich then returns the user's bill. Web services can also be integrated together to provide greater value-add. For example, a travel management web service may make use of the capabilities of the web services providing car hire, hotel bookings and flight reservations. Or a video-on-demand web service may make use of a communication service that delivers the video stream.

The first Web services were built for passing remote procedure calls (RPCs) over the Web. The idea took off quickly and resulted in a large collection of standards. Surprisingly, these standards were defined with little consideration to the contemporary practice; sometimes before there were any implementations to standardize. The end result of this premature standardization was confusion, rather than order that standards usually bring. In response, an alternative style of Web services, built according to the rules of the Web, began to appear. These (so-called RESTful) Web services are maturing, or, more precisely: people are re-learning to use the tried-and-true standards of the Web and applying them when building Web services.

\subsection{SOAP}
In 1998, a new remote procedure call protocol was defined with the ability to go through firewalls, this new protocol was named as Simple Object Access Protocol (SOAP), it was designed to be a platform and language-neutral alternative to previous middleware technologies like CORBA and DCOM. Its first public appearance was an Internet public draft (submitted to the IETF\footnote{Internet Enginnering Task Force}) in 1999; shortly thereafter, in December of 1999, SOAP 1.0 was released. In May of 2000 the 1.1 version was submitted to the W3C where it formed the heart of the emerging Web Services technologies. The current version is 1.2, finalized in 2005. From its definition up to its standardization, SOAP has evolved quite a lot to become more flexible in terms of the data to be transferred and also protocol agnostic (supporting different bindings of WSDL\footnote{Web Services Description Language})\cite{Pautasso:2007}.

Together with WSDL and XML Schema, SOAP has become the standard for exchanging XML-based messages. It was also designed from the ground up to be extensible, so that other standards could be integrated into it --and there have been many, often collectively referred to as WS-*\footnote{The term WS-* is used to refer to services based on the SOAP standard, and other WS-* standards (e.g WS-Addressing, WS-Security) defined specifically for Web services.}. Hence much of the perceived complexity of SOAP, comes from the multitude of standards which have evolved around it\cite{Spies:2008}.

\subsection{REST}
Much in the way that Ruby on Rails was a reaction to more complex web application architectures, the emergence of the RESTful style of web services was a reaction to the more heavy-weight SOAP-based standards. In RESTful web services, the emphasis is on simple point-to-point communication over HTTP using plain old XML (POX)\cite{Spies:2008}.

The origin of the term ``REST'' comes from the doctoral thesis from Roy Fielding\cite{Fielding00Phd} (who also participated in developing HTTP 1.0 and HTTP 1.1), where he described the concept of \textit{Representative State Transfer} (REST). He saw REST as a way to help communicate the basic concepts underlying the Web. In order to understand REST, it is necessary to understand the definition of resource, representation and state, in the context of web services.
\begin{description}
\item[Resource] Can be anything, wether it be a physical object or an abstract concept. As long as something is important enough to be referenced as a thing itself, it can be exposed as a resource. Usually a resource is something that can be stored in computer an represented as a stream of bits.
\item[Representation] Is any useful information about the state of a resource. A resource may have multiple different representations.
\item[State] In REST there are two types of state, one is resource state wich is information about a resource, and the other is application state, wich is information about the path the client has taken through the application. Resource state stays on the server and application state only lives in the client.
\end{description}

REST provides a set of architectural constraints that, when applied as a whole, emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems\cite{Fielding00Phd}.

\subsection{Principles of Web services}
Roy Fielding documented REST based on the principles that emerged as the Web evolved. He noticed that Web servers, clients, and intermediaries shared some principles that gave them extensibility to work on the large-scale of the Internet. He identified four principles of REST (which he called constraints):
\begin{itemize}
\item Identification of resources.
\item Manipulation of resources through representations.
\item Self-descriptive messages.
\item Hypermedia as the engine of application state (abbreviated HATEOAS).
\end{itemize}

These principles combine into a short and consistent metaphor of systems and interactions that make up the Web. The building blocks of the Web are called resources. A resource is anything that can be named as a target of hypertext (e.g. a file, a script, a collection of resources). In response to a request for a resource, the client receives a representation of that resource, which may have a different format than the resource owned by the server. Resources are manipulated via messages that have standard meanings; on the Web, these messages are the HTTP methods. The fourth principle means that the state of any client-server interaction is kept in the hypermedia they exchange, i.e., links, or URIs. Any state information is passed between the client and the server in each message, thus keeping them both stateless.

It's easy to evaluate any design with such a simple metaphor. Any discrepancies will be easy to identify. However this simplicity is deceptive, if one tries to simplify it even more, bad things happen.

WS-* services do not have a single metaphor. Web Services Architecture document\cite{Booth:2004} from W3C describes four architectural models of WS-*, but does not explain how they relate. One of the models is the Resource Oriented Model (which would imply REST), but as their definition of Web services suggests, the systems they consider are limited to various standards: SOAP, WSDL, and others. New capabilities are added in the form of new standards. There is no general description of the relationship between WS-* standards. Their definitions are constrained only by the compliance with SOAP, WSDL, and the XML schema for defining additional ``stickers'' in the SOAP envelope.

\subsection{Comparison between REST and WS-* Principles}
Choosing the best option when developing a web service is not a matter of luck, but the result of analyzing the advantages and disadvantages of each of the different models, and choosing one that fits the needs of the problem to solve. Two attempts to compare REST and WS-* services at the abstract level are described below:

\begin{description}
\item[Pautasso et al. study] In the most comprehensive comparison to date, Pautasso et al.\cite{Pautasso:2008} compare RESTful and WS-* services on 3 levels: 1) architectural principles, 2) conceptual decisions, and 3) technology decisions.

On the level of \emph{architectural principles}, Pautasso et al. analyze 3 principles (protocol layering, dealing with heterogeneity, and loose coupling) and note that both styles support these 3 principles. However, they can identify only one aspect common to both styles -- loose coupling to location (or dynamic late binding). Consequently, they conclude that it's not possible to make a decision at this level and proceed with more detailed analysis. At the level of \emph{conceptual decisions}, they compare 9 different decisions and find that RESTful services require the designer to make 8 of them, versus only 5 for WS-*. However, WS-* have many more alternatives than RESTful services. Finally, in the \emph{technology} comparison, they identify 10 technologies that are relevant to both styles. In this comparison, WS-* once again offer many more alternatives than their RESTful counterparts.

Based on these results, the authors recommend using REST for ad hoc integration and using WS-* for enterprise-level application integration where transactions, reliability, and message-level security are critical. This study illustrates two key difficulties of performing convincing comparisons of broad ideas, such as Web service styles. First, it's difficult to select the most relevant principles to compare. Second, once the principles are selected, it's difficult to identify choices that are shared by the competing ideas.

Pautasso et al do not explain why they selected protocol layering, dealing with heterogeneity, and loose coupling as the only architectural principles to compare. However, in their analysis, \textit{``key -ilities''} (security, reliability) are only mentioned at lowest level of comparison, the technology decisions. Moreover, they shy away from comparing concepts that are relevant at the enterprise level (transactions, reliability, message-level security), even though they cite these very concepts in their concluding recommendation.

The actual comparison has two problems. First, they use the \emph{numbers} of architectural decisions and available alternatives to choose which style is better. But counting is hardly the right metric -- not every decision point has the same weight. Second, most decision points on every level have 2 options, 1 for each style, indicating that they actually have nothing in common. Only in a few cases do both styles require a decision on the same question.

Nevertheless, this paper is the best-conducted comparison of principles available today. It's unbiased, thoroughly researched, and it examines multiple points of view.

\item[Richardson and Ruby Study] A second comparison of note is presented in the book, ``RESTful Web Services''\cite{RichardsonRuby:2007}. The authors, Richardson and Ruby, discuss the principles that are relevant to all systems available on the Web. Even though their book is biased toward RESTful Web services, the principles they discuss would be a better starting point for making a fair comparison between the two styles.

They identify four system properties of RESTful services: 1) uniform interface, 2) addressability, 3) statelessness, and 4) connectedness. In RESTful Web services, these properties are embodied in resources, URIs, representations, and the links between them. On the contrary, WS-* services exhibits three of these four properties.

Addressability and some form of connectedness are embedded in the WSDL definition of bindings and ports. Many WS-* services are stateless (although it is not an explicit requirement). Having a uniform interface shared by all services is the only property not supported by WS-*. Since these properties are relevant to both, they are a good choice for comparison.

Richardson and Ruby use a similar approach to evaluate how RESTful Web services offer capabilities which are important for enterprise-level integration. They show how to implement transactions, reliability and message-level security (concepts that Pautasso et al mention, but do not discuss) using REST.
\end{description}

From the previous comparisons, it's notable that both styles of Web services possess certain characteristics that guide their design and development, although they are defined in ways that make it difficult to compare them side-by-side, therefore it is important to take into consideration the common characteristics since the election of the correct style, will be fundamental in the performance of the web service.

RESTful Web services (and Web services in general) pose the first big test of the principles of REST, as identified by Fielding. Even though RESTful services might look like typical Web system, they are not, and WS-* services are clearly different. Up until a few years ago, there was a simple dichotomy between REST and WS-*. RESTful services were used only for simple, public services. In contrast, enterprise standards, tools vendors, and the research community were only concerned with WS-* services, but this is no longer the case, and nowadays both styles are being used in all domains.

The latter is caused mainly because REST web services have evolve to become an alternative to RPC based web services. According to Feng et. al.\cite{Feng:2009}, RESTful web services architecture is better in scalability, coupling and performance, and is likely to become the mainstream technology of web services. Considering this, and based on the problem to be solved, REST web services would be the best option.
